<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Camera Stream with Mirror Effect</title>
    <style>
      #container {
        display: flex;
        justify-content: center;
      }
      #videoElement {
        display: none; /* 不显示视频元素 */
      }
      #result {
        width: 100%; /* 设置处理结果的宽度为100% */
      }
    </style>
  </head>
  <body>
    <h1>Camera Stream Predicted</h1>
    <div id="container">
      <video id="videoElement" width="640" height="480" autoplay></video>
      <canvas id="resultCanvas" width="640" height="480" ></canvas>
    </div>
    <div>
      <button id="startButton">Start Recording</button>
      <button id="stopButton">Stop Recording</button>
      <button id="jumpFrame">jumpFrame</button>
      <div id="jumptext"></div>
      <button id="synthesizeButton">Synthesize Video</button>
      <a id="downloadLink" style="display: none">Download Video</a>
    </div>
    <script src="static/fix-webm-duration.js"></script>
    <script>

      // 获取视频流
      const video = document.getElementById("videoElement");
      const startButton = document.getElementById("startButton");
      const stopButton = document.getElementById("stopButton");
      const jumpFrame = document.getElementById("jumpFrame");
      const jumptext=document.getElementById("jumptext");
      const downloadLink = document.getElementById("downloadLink");
      
      // 获取 canvas 元素及其上下文
        const resultCanvas = document.getElementById("resultCanvas");
        const resultContext = resultCanvas.getContext("2d");
        let jump=true;
        let jpcount=0;
        let chunks = [];
        let dingshi;
        var startTime;

      // 获取摄像头视频流
      navigator.mediaDevices
        .getUserMedia({ video: true, audio:true })
        .then((stream) => {
          video.srcObject = stream;
          const canvasStream = resultCanvas.captureStream(30);
          const audioTrack = stream.getAudioTracks()[0];
          const videoTrack = canvasStream.getVideoTracks()[0]; // 假设只有一个视频轨道 
                    // 创建新的 MediaStream
            const combinedStream = new MediaStream();

            // 将音频轨道添加到新的 MediaStream 中
            combinedStream.addTrack(audioTrack);
            combinedStream.addTrack(videoTrack);


          mediaRecorder = new MediaRecorder(combinedStream);

          
        //   mediaRecorder = new MediaRecorder(canvasStream);
          mediaRecorder.ondataavailable = function (event) {
            chunks.push(event.data);
          };
          mediaRecorder.onstop = function () {

            const duration = Date.now() - startTime;
            const blob = new Blob(chunks, { type: "video/webm;codecs=vp8,opus" });
            //修复无法拖动进度条的问题
            ysFixWebmDuration(blob, duration, function (fixedBlob) {
            const url = URL.createObjectURL(new Blob([fixedBlob], { type: 'video/webm;codecs=vp8,opus' }));
            downloadLink.href = url;
            downloadLink.download = "recorded-video.webm";
            downloadLink.style.display = "block";});
          };
        })
        .catch((err) => {
          console.error("Error accessing media devices: ", err);
        });

        const synthesizeButton = document.getElementById("synthesizeButton");

synthesizeButton.addEventListener("click", () => {
    fetch("/synthesize_video", {
        method: "POST",
        headers: {
            "Content-Type": "application/json",
        },
    })
    .then((response) => {
        if (response.ok) {
            console.log("Video synthesis completed successfully");
        } else {
            console.error("Video synthesis failed");
        }
    })
    .catch((error) => {
        console.error("Error triggering video synthesis: ", error);
    });
});

      // 开始录制
      startButton.addEventListener("click", () => {
        chunks = [];
        mediaRecorder.start();
        startTime=Date.now();
        startButton.disabled = true;
        stopButton.disabled = false;
        // 在视频流上定时绘制
        dingshi = setInterval(function () {
          // 将帧数据转换为base64编码的图像数据
          const imageData = captureFrame(video);
          // 发送数据到服务器
          sendData(imageData);
        }, 30); // 每30ms发送一次帧
      });

// 在 stopButton 的 click 事件监听器中
stopButton.addEventListener("click", () => {
    mediaRecorder.stop();
    startButton.disabled = false;
    stopButton.disabled = true;
    clearInterval(dingshi);

    // 获取音频 Blob
    const audioBlob = new Blob(chunks.filter(chunk => chunk.type.includes('audio')), { type: 'audio/mp3' });
    console.log(audioBlob);
    // 创建一个指向音频 Blob 的 URL
    const audioURL = URL.createObjectURL(audioBlob);
    
    // 设置下载链接的 href 属性为音频 Blob 的 URL
    downloadLink.href = audioURL;
    downloadLink.download = "recorded-audio.mp3"; // 设置下载文件的名称
    downloadLink.style.display = "block"; // 显示下载链接

    // 发送音频 Blob 到后端
    sendAudioToBackend(audioBlob);
});

// 发送音频 Blob 到后端的函数
function sendAudioToBackend(audioBlob) {
    const formData = new FormData();
    formData.append('audio', audioBlob);
    fetch("/process_audio", {
        method: "POST",
        body: formData
    })
    .then(response => {
        if (response.ok) {
            console.log("音频发送到后端成功");
        } else {
            console.error("音频发送到后端失败");
        }
    })
    .catch(error => {
        console.error("发送音频数据到后端出错: ", error);
    });
}

      jumpFrame.addEventListener("click", () => {
        jump=!jump;
        jumptext.innerText=jump;

      });    

      // 获取视频帧并转换为 base64 编码的图像数据
      function captureFrame(video) {
        const canvas = document.createElement("canvas");
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        const context = canvas.getContext("2d");
        context.drawImage(video, 0, 0, canvas.width, canvas.height);
        return canvas.toDataURL("image/jpeg");
      }

      // 发送数据到服务器
      function sendData(imageData) {
        if(jump){
            jpcount++;
        }
        else{
            jpcount=1;
        }
        fetch("/process_frame", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          body: JSON.stringify({ image_data: imageData ,jumpORnot:jpcount%2}),
        })
          .then((response) => response.text())
          .then((data) => {
                // 渲染服务器处理后的图像到 canvas 上
                const img = new Image();
                img.onload = function() {
                    // 清除之前的渲染
                    resultContext.clearRect(0, 0, resultCanvas.width, resultCanvas.height);
                    // 将图像渲染到 canvas 上
                    resultContext.drawImage(img, 0, 0, resultCanvas.width, resultCanvas.height);
                };
                img.src = "data:image/jpeg;base64," + data;
          })
          .catch((error) => {
            console.error("Error sending data to server: ", error);
          });
      }
    </script>
  </body>
</html>
